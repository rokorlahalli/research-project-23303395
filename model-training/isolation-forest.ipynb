{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e71d41b-59b3-40a0-9f71-9fb45c801386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9932    0.9910    0.9921    388059\n",
      "           1     0.1077    0.1387    0.1213      3036\n",
      "\n",
      "    accuracy                         0.9844    391095\n",
      "   macro avg     0.5505    0.5648    0.5567    391095\n",
      "weighted avg     0.9864    0.9844    0.9854    391095\n",
      "\n",
      "\n",
      "ğŸ“‰ Confusion Matrix:\n",
      "[[384572   3487]\n",
      " [  2615    421]]\n",
      "âœ… Model, scaler, and predictions saved.\n"
     ]
    }
   ],
   "source": [
    "# ğŸ“¦ Install dependencies (if needed)\n",
    "!pip install -q pandas scikit-learn\n",
    "\n",
    "# ğŸ“Œ Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import joblib  # for saving model\n",
    "\n",
    "# ğŸ“¥ Load dataset from S3 or local\n",
    "# If using S3, use: pd.read_csv(\"s3://your-bucket/preprocessed_dataset.csv\")\n",
    "df = pd.read_csv(\"preprocessed_dataset_0510.csv\", parse_dates=[\"timestamp\"])\n",
    "\n",
    "# ğŸ¯ Select features and label\n",
    "features = [\n",
    "    \"cpu_usage\", \"memory_usage\", \"net_receive\", \"net_transmit\",\n",
    "    \"fs_reads_bytes\", \"fs_writes_bytes\", \"restarts\"\n",
    "]\n",
    "X = df[features]\n",
    "y = df[\"label\"]\n",
    "\n",
    "# ğŸ§¼ Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# ğŸ§  Train Isolation Forest\n",
    "model = IsolationForest(\n",
    "    n_estimators=100,\n",
    "    contamination=0.01,  # manually chosen\n",
    "    max_samples='auto',\n",
    "    random_state=42\n",
    ")\n",
    "model.fit(X_scaled)\n",
    "\n",
    "# ğŸ”® Predict\n",
    "y_pred = model.predict(X_scaled)\n",
    "y_pred = np.where(y_pred == -1, 1, 0)  # convert -1/1 to 1/0\n",
    "\n",
    "# ğŸ“Š Evaluation\n",
    "print(\"ğŸ“Š Classification Report:\")\n",
    "print(classification_report(y, y_pred, digits=4))\n",
    "\n",
    "print(\"\\nğŸ“‰ Confusion Matrix:\")\n",
    "print(confusion_matrix(y, y_pred))\n",
    "\n",
    "# ğŸ’¾ Save model & scaler for deployment\n",
    "joblib.dump(model, \"iforest_model.pkl\")\n",
    "joblib.dump(scaler, \"iforest_scaler.pkl\")\n",
    "\n",
    "# ğŸ“ Save predictions (optional)\n",
    "df[\"predicted_label\"] = y_pred\n",
    "df.to_csv(\"iforest_predictions.csv\", index=False)\n",
    "\n",
    "print(\"âœ… Model, scaler, and predictions saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c918647c-126c-4b07-881f-291eea61c6d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
