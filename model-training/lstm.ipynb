{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6144f1bc-a8d9-4e88-aad8-5e748d566bb0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 391095 entries, 0 to 391094\n",
      "Data columns (total 11 columns):\n",
      " #   Column           Non-Null Count   Dtype              \n",
      "---  ------           --------------   -----              \n",
      " 0   timestamp        391095 non-null  datetime64[ns, UTC]\n",
      " 1   pod              391095 non-null  object             \n",
      " 2   container        391095 non-null  object             \n",
      " 3   cpu_usage        391095 non-null  float64            \n",
      " 4   label            391095 non-null  int64              \n",
      " 5   memory_usage     391095 non-null  float64            \n",
      " 6   net_receive      391095 non-null  float64            \n",
      " 7   net_transmit     391095 non-null  float64            \n",
      " 8   fs_reads_bytes   391095 non-null  float64            \n",
      " 9   fs_writes_bytes  391095 non-null  float64            \n",
      " 10  restarts         391095 non-null  float64            \n",
      "dtypes: datetime64[ns, UTC](1), float64(7), int64(1), object(2)\n",
      "memory usage: 32.8+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None,\n",
       "                   timestamp                          pod  container  \\\n",
       " 0 2025-09-22 23:00:00+00:00  anomaly-load-29308860-54nq2         k6   \n",
       " 1 2025-09-22 23:00:00+00:00  anomaly-load-29308920-bckkd         k6   \n",
       " 2 2025-09-22 23:00:00+00:00  anomaly-load-29309220-6hl4k         k6   \n",
       " 3 2025-09-22 23:00:00+00:00        cart-5d9c9599cb-89l9k       cart   \n",
       " 4 2025-09-22 23:00:00+00:00   catalogue-6878884699-n4xl5  catalogue   \n",
       " \n",
       "    cpu_usage  label  memory_usage  net_receive  net_transmit  fs_reads_bytes  \\\n",
       " 0   0.000000      0           0.0          0.0           0.0             0.0   \n",
       " 1   0.000000      0           0.0          0.0           0.0             0.0   \n",
       " 2   0.000000      0           0.0          0.0           0.0             0.0   \n",
       " 3   0.000550      0    45854720.0          0.0           0.0             0.0   \n",
       " 4   0.000688      0    52903936.0          0.0           0.0             0.0   \n",
       " \n",
       "    fs_writes_bytes  restarts  \n",
       " 0              0.0       0.0  \n",
       " 1              0.0       0.0  \n",
       " 2              0.0       0.0  \n",
       " 3              0.0       0.0  \n",
       " 4              0.0       0.0  )"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Re-import necessary libraries due to environment reset\n",
    "import pandas as pd\n",
    "\n",
    "# Reload the dataset\n",
    "df = pd.read_csv(\"preprocessed_dataset_0510.csv\", parse_dates=[\"timestamp\"])\n",
    "\n",
    "# Preview structure and first few rows\n",
    "df.info(), df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04e5b8d-3c73-4d06-9352-135c6f10a67b",
   "metadata": {},
   "source": [
    "# Time sequencing for LSTM part starts here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e208233e-2f2a-43ba-b8b1-d16c5feb87a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14913, 30, 7), (14913,))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Limit dataset to key services for faster LSTM prep\n",
    "key_containers = ['cart', 'catalogue', 'web']\n",
    "df_filtered = df[df['container'].isin(key_containers)]\n",
    "\n",
    "# Sort and reduce to last 5000 entries per pod\n",
    "df_sequences = (\n",
    "    df_filtered.sort_values(by=[\"pod\", \"timestamp\"])\n",
    "    .groupby(\"pod\")\n",
    "    .tail(5000)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# Normalize features\n",
    "FEATURE_COLS = [\n",
    "    \"cpu_usage\", \"memory_usage\", \"net_receive\", \"net_transmit\",\n",
    "    \"fs_reads_bytes\", \"fs_writes_bytes\", \"restarts\"\n",
    "]\n",
    "WINDOW_SIZE = 30\n",
    "scaler = MinMaxScaler()\n",
    "df_sequences[FEATURE_COLS] = scaler.fit_transform(df_sequences[FEATURE_COLS])\n",
    "\n",
    "# Build LSTM sequences\n",
    "X, y = [], []\n",
    "for pod_name, pod_df in df_sequences.groupby(\"pod\"):\n",
    "    pod_df = pod_df.reset_index(drop=True)\n",
    "    for i in range(len(pod_df) - WINDOW_SIZE + 1):\n",
    "        window = pod_df.loc[i:i+WINDOW_SIZE-1, FEATURE_COLS].values\n",
    "        label = pod_df.loc[i+WINDOW_SIZE-1, \"label\"]\n",
    "        X.append(window)\n",
    "        y.append(label)\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62930d33-8b3c-4ffc-a1cd-ed93de1e2b12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow==2.15\n",
      "  Downloading tensorflow-2.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.4 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow==2.15)\n",
      "  Downloading absl_py-2.3.1-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow==2.15)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=23.5.26 (from tensorflow==2.15)\n",
      "  Downloading flatbuffers-25.9.23-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow==2.15)\n",
      "  Downloading gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tensorflow==2.15) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tensorflow==2.15) (3.13.0)\n",
      "Collecting libclang>=13.0.0 (from tensorflow==2.15)\n",
      "  Downloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting ml-dtypes~=0.2.0 (from tensorflow==2.15)\n",
      "  Downloading ml_dtypes-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tensorflow==2.15) (1.26.4)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow==2.15)\n",
      "  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tensorflow==2.15) (24.2)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 (from tensorflow==2.15)\n",
      "  Downloading protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
      "Requirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tensorflow==2.15) (80.9.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tensorflow==2.15) (1.17.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow==2.15)\n",
      "  Downloading termcolor-3.2.0-py3-none-any.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tensorflow==2.15) (4.15.0)\n",
      "Collecting wrapt<1.15,>=1.11.0 (from tensorflow==2.15)\n",
      "  Downloading wrapt-1.14.2-cp310-cp310-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (6.5 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow==2.15)\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.37.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow==2.15)\n",
      "  Downloading grpcio-1.76.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.7 kB)\n",
      "Collecting tensorboard<2.16,>=2.15 (from tensorflow==2.15)\n",
      "  Downloading tensorboard-2.15.2-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting tensorflow-estimator<2.16,>=2.15.0 (from tensorflow==2.15)\n",
      "  Downloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting keras<2.16,>=2.15.0 (from tensorflow==2.15)\n",
      "  Downloading keras-2.15.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting google-auth<3,>=1.6.3 (from tensorboard<2.16,>=2.15->tensorflow==2.15)\n",
      "  Downloading google_auth-2.43.0-py2.py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting google-auth-oauthlib<2,>=0.5 (from tensorboard<2.16,>=2.15->tensorflow==2.15)\n",
      "  Downloading google_auth_oauthlib-1.2.3-py3-none-any.whl.metadata (3.1 kB)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<2.16,>=2.15->tensorflow==2.15)\n",
      "  Downloading markdown-3.10-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15) (2.32.5)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.16,>=2.15->tensorflow==2.15)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15) (3.1.3)\n",
      "Collecting cachetools<7.0,>=2.0.0 (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15)\n",
      "  Downloading cachetools-6.2.2-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15)\n",
      "  Downloading pyasn1_modules-0.4.2-py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15) (4.7.2)\n",
      "Collecting google-auth<3,>=1.6.3 (from tensorboard<2.16,>=2.15->tensorflow==2.15)\n",
      "  Downloading google_auth-2.41.1-py2.py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting requests-oauthlib>=0.7.0 (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow==2.15)\n",
      "  Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15) (2025.10.5)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from rsa<5,>=3.1.4->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15) (0.6.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow==2.15) (0.45.1)\n",
      "Collecting oauthlib>=3.0.0 (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow==2.15)\n",
      "  Downloading oauthlib-3.3.1-py3-none-any.whl.metadata (7.9 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow==2.15) (3.0.3)\n",
      "Downloading tensorflow-2.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (475.2 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m475.2/475.2 MB\u001b[0m \u001b[31m55.5 MB/s\u001b[0m  \u001b[33m0:00:05\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading grpcio-1.76.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (6.6 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m172.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading keras-2.15.0-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m134.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ml_dtypes-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m85.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
      "Downloading tensorboard-2.15.2-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m121.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cachetools-6.2.2-py3-none-any.whl (11 kB)\n",
      "Downloading google_auth_oauthlib-1.2.3-py3-none-any.whl (19 kB)\n",
      "Downloading google_auth-2.41.1-py2.py3-none-any.whl (221 kB)\n",
      "Downloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Downloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl (441 kB)\n",
      "Downloading wrapt-1.14.2-cp310-cp310-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (76 kB)\n",
      "Downloading absl_py-2.3.1-py3-none-any.whl (135 kB)\n",
      "Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading flatbuffers-25.9.23-py2.py3-none-any.whl (30 kB)\n",
      "Downloading gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Downloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.5/24.5 MB\u001b[0m \u001b[31m259.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading markdown-3.10-py3-none-any.whl (107 kB)\n",
      "Downloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Downloading pyasn1_modules-0.4.2-py3-none-any.whl (181 kB)\n",
      "Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Downloading oauthlib-3.3.1-py3-none-any.whl (160 kB)\n",
      "Downloading tensorflow_io_gcs_filesystem-0.37.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.1 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m186.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading termcolor-3.2.0-py3-none-any.whl (7.7 kB)\n",
      "Installing collected packages: libclang, flatbuffers, wrapt, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, pyasn1-modules, protobuf, opt-einsum, oauthlib, ml-dtypes, markdown, keras, grpcio, gast, cachetools, astunparse, absl-py, requests-oauthlib, google-auth, google-auth-oauthlib, tensorboard, tensorflow\n",
      "\u001b[2K  Attempting uninstall: wraptâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 1/24\u001b[0m [flatbuffers]\n",
      "\u001b[2K    Found existing installation: wrapt 2.0.0â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 1/24\u001b[0m [flatbuffers]\n",
      "\u001b[2K    Uninstalling wrapt-2.0.0:â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 1/24\u001b[0m [flatbuffers]\n",
      "\u001b[2K      Successfully uninstalled wrapt-2.0.0â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 1/24\u001b[0m [flatbuffers]\n",
      "\u001b[2K  Attempting uninstall: protobufm\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 7/24\u001b[0m [pyasn1-modules]mator]esystem]\n",
      "\u001b[2K    Found existing installation: protobuf 6.31.1â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 7/24\u001b[0m [pyasn1-modules]\n",
      "\u001b[2K    Uninstalling protobuf-6.31.1:0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 8/24\u001b[0m [protobuf]s]\n",
      "\u001b[2K      Successfully uninstalled protobuf-6.31.1â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 8/24\u001b[0m [protobuf]\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24/24\u001b[0m [tensorflow]4\u001b[0m [tensorflow]]\n",
      "\u001b[1A\u001b[2KSuccessfully installed absl-py-2.3.1 astunparse-1.6.3 cachetools-6.2.2 flatbuffers-25.9.23 gast-0.6.0 google-auth-2.41.1 google-auth-oauthlib-1.2.3 grpcio-1.76.0 keras-2.15.0 libclang-18.1.1 markdown-3.10 ml-dtypes-0.2.0 oauthlib-3.3.1 opt-einsum-3.4.0 protobuf-4.25.8 pyasn1-modules-0.4.2 requests-oauthlib-2.0.0 tensorboard-2.15.2 tensorboard-data-server-0.7.2 tensorflow-2.15.0 tensorflow-estimator-2.15.0 tensorflow-io-gcs-filesystem-0.37.1 termcolor-3.2.0 wrapt-1.14.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow==2.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "593d66c1-2ce2-4f02-a391-3f2cfb6d5a51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-18 13:01:13.601170: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-11-18 13:01:13.601209: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-11-18 13:01:13.602363: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-11-18 13:01:13.609814: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-11-18 13:01:14.667758: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-11-18 13:01:20.314826: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:274] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "131/131 [==============================] - 7s 32ms/step - loss: 0.1293 - accuracy: 0.9780 - val_loss: 0.0850 - val_accuracy: 0.9832\n",
      "Epoch 2/20\n",
      "131/131 [==============================] - 3s 26ms/step - loss: 0.0800 - accuracy: 0.9850 - val_loss: 0.0850 - val_accuracy: 0.9832\n",
      "Epoch 3/20\n",
      "131/131 [==============================] - 3s 27ms/step - loss: 0.0793 - accuracy: 0.9850 - val_loss: 0.0842 - val_accuracy: 0.9832\n",
      "Epoch 4/20\n",
      "131/131 [==============================] - 3s 26ms/step - loss: 0.0783 - accuracy: 0.9850 - val_loss: 0.0829 - val_accuracy: 0.9832\n",
      "Epoch 5/20\n",
      "131/131 [==============================] - 3s 26ms/step - loss: 0.0771 - accuracy: 0.9850 - val_loss: 0.0797 - val_accuracy: 0.9832\n",
      "Epoch 6/20\n",
      "131/131 [==============================] - 3s 26ms/step - loss: 0.0720 - accuracy: 0.9850 - val_loss: 0.0721 - val_accuracy: 0.9832\n",
      "Epoch 7/20\n",
      "131/131 [==============================] - 3s 26ms/step - loss: 0.0660 - accuracy: 0.9850 - val_loss: 0.0671 - val_accuracy: 0.9832\n",
      "Epoch 8/20\n",
      "131/131 [==============================] - 3s 26ms/step - loss: 0.0606 - accuracy: 0.9853 - val_loss: 0.0618 - val_accuracy: 0.9832\n",
      "Epoch 9/20\n",
      "131/131 [==============================] - 3s 26ms/step - loss: 0.0554 - accuracy: 0.9866 - val_loss: 0.0603 - val_accuracy: 0.9837\n",
      "Epoch 10/20\n",
      "131/131 [==============================] - 3s 26ms/step - loss: 0.0530 - accuracy: 0.9861 - val_loss: 0.0568 - val_accuracy: 0.9837\n",
      "Epoch 11/20\n",
      "131/131 [==============================] - 3s 26ms/step - loss: 0.0524 - accuracy: 0.9871 - val_loss: 0.0562 - val_accuracy: 0.9847\n",
      "Epoch 12/20\n",
      "131/131 [==============================] - 3s 26ms/step - loss: 0.0511 - accuracy: 0.9875 - val_loss: 0.0589 - val_accuracy: 0.9852\n",
      "Epoch 13/20\n",
      "131/131 [==============================] - 3s 26ms/step - loss: 0.0480 - accuracy: 0.9869 - val_loss: 0.0528 - val_accuracy: 0.9875\n",
      "Epoch 14/20\n",
      "131/131 [==============================] - 3s 26ms/step - loss: 0.0472 - accuracy: 0.9873 - val_loss: 0.0499 - val_accuracy: 0.9875\n",
      "Epoch 15/20\n",
      "131/131 [==============================] - 3s 26ms/step - loss: 0.0457 - accuracy: 0.9883 - val_loss: 0.0516 - val_accuracy: 0.9875\n",
      "Epoch 16/20\n",
      "131/131 [==============================] - 3s 26ms/step - loss: 0.0446 - accuracy: 0.9886 - val_loss: 0.0528 - val_accuracy: 0.9871\n",
      "Epoch 17/20\n",
      "131/131 [==============================] - 3s 27ms/step - loss: 0.0437 - accuracy: 0.9887 - val_loss: 0.0499 - val_accuracy: 0.9875\n",
      "Epoch 18/20\n",
      "131/131 [==============================] - 3s 26ms/step - loss: 0.0426 - accuracy: 0.9893 - val_loss: 0.0475 - val_accuracy: 0.9880\n",
      "Epoch 19/20\n",
      "131/131 [==============================] - 3s 26ms/step - loss: 0.0417 - accuracy: 0.9896 - val_loss: 0.0467 - val_accuracy: 0.9880\n",
      "Epoch 20/20\n",
      "131/131 [==============================] - 3s 26ms/step - loss: 0.0421 - accuracy: 0.9893 - val_loss: 0.0478 - val_accuracy: 0.9890\n",
      "140/140 [==============================] - 2s 7ms/step\n",
      "ðŸ“Š Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      4406\n",
      "           1       0.68      0.47      0.56        68\n",
      "\n",
      "    accuracy                           0.99      4474\n",
      "   macro avg       0.84      0.73      0.78      4474\n",
      "weighted avg       0.99      0.99      0.99      4474\n",
      "\n",
      "ðŸ“‰ Confusion Matrix:\n",
      "[[4391   15]\n",
      " [  36   32]]\n",
      "âœ… Model saved as lstm_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Assuming X and y already exist in memory\n",
    "# If not, load them from files: X = np.load('X.npy'); y = np.load('y.npy')\n",
    "\n",
    "# Train-test split (70-30)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Define the LSTM model\n",
    "model = Sequential([\n",
    "    LSTM(64, input_shape=(X.shape[1], X.shape[2]), return_sequences=True),\n",
    "    Dropout(0.2),\n",
    "    LSTM(32),\n",
    "    Dropout(0.2),\n",
    "    Dense(1, activation='sigmoid')  # Binary classification\n",
    "])\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model with early stopping\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=20,\n",
    "    batch_size=64,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[early_stop],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Evaluation\n",
    "y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "\n",
    "print(\"ðŸ“Š Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"ðŸ“‰ Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Save model\n",
    "model.save(\"lstm_model.h5\")\n",
    "print(\"âœ… Model saved as lstm_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6475942c-2cd0-4774-b206-3068022fd884",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
